{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# pip Installtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peHC3XLK8efs",
        "outputId": "a516f3b2-3783-45f2-98b3-fbcb2ddd4cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /home/gustavokpc/.local/lib/python3.10/site-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets) (2023.5.0)\n",
            "Requirement already satisfied: aiohttp in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /home/gustavokpc/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gustavokpc/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3>=1.25.10 in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.26.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gustavokpc/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjtHnm8VAkiN",
        "outputId": "0cb7f29b-963b-44c2-b209-fc4407ebd4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /home/gustavokpc/.local/lib/python3.10/site-packages (4.34.1)\n",
            "Requirement already satisfied: datasets in /home/gustavokpc/.local/lib/python3.10/site-packages (2.12.0)\n",
            "Requirement already satisfied: evaluate in /home/gustavokpc/.local/lib/python3.10/site-packages (0.4.1)\n",
            "Requirement already satisfied: filelock in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/gustavokpc/.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: xxhash in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets) (2023.5.0)\n",
            "Requirement already satisfied: aiohttp in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: responses<0.19 in /home/gustavokpc/.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/gustavokpc/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gustavokpc/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3>=1.25.10 in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.26.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gustavokpc/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: ipywidgets in /home/gustavokpc/.local/lib/python3.10/site-packages (8.1.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipywidgets) (0.1.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
            "Requirement already satisfied: backcall in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: decorator in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: matplotlib-inline in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /home/gustavokpc/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /home/gustavokpc/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/gustavokpc/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /home/gustavokpc/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5TymxnIG7cDu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 11:00:53.401442: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-15 11:00:53.437282: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-15 11:00:53.620760: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-15 11:00:53.622599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-15 11:00:54.453378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset, Dataset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, matthews_corrcoef\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "import evaluate\n",
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 11:00:58.529359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-15 11:00:58.530073: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jan 15 11:01:18 2024       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   49C    P8    13W / 115W |      6MiB /  6144MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2115      G   /usr/bin/gnome-shell                2MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hugging Face Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f5996a197da4490ea9d90911b63f6db7",
            "ee9ce7b5e22a455996c0eb94918d201e",
            "765c03d7611841e18cd064ee0f07ea6c",
            "1bf403a3b41b434899b24e55158d9001",
            "3a397ebb3c744a14bd764df19b5e7b01",
            "afc3f442c128481cac2145f1b88e2982",
            "7b13e05ab95240509c7e1790c9b1fbb5",
            "808cdc93356d41f79eb0fa1975495921",
            "d07b4922d6c04754a96de47fd62033aa",
            "475713ce145f4fc1beab59de46892f5a",
            "c20138bfc36c4942a887f9c097c2e3f8",
            "a95d32b93d8444be88b23e6951b8d079",
            "ad80b1c96a2b43a1b53bfe2880eea49f",
            "2026e5a1dc9b488b9a45cdbbdedfec8c",
            "372c4e4950ee4122b5b6d0dcde672d56",
            "d012a7fc1a1d4d139c21cdd452183c09",
            "79d1820f406c4bad995f06db705021e2",
            "0c80641d1bfc43aaa140a02d234ab218",
            "90f05997c4ee42529f8c43685a7c88d9",
            "8ffea4a72f2a42d194eea491ba3522e1",
            "02ca282163e84911a6bbb5a89e6cb8e0",
            "cb21581ed1f546f6b340b843a51b3d10",
            "2dc69d8658aa4196ada660c98e20c4cd",
            "a034f64f0a9944088944dd21e67e83df",
            "ebad54fcdb4f401b87690e111a76241e",
            "943bf451794b4a98ac34d22ff3e18153",
            "1b04d96bc5ca472382d87b25dd00e76a",
            "23e24c02abfb4f90bc07dde978849110",
            "13314f40c2cc45e2b3bd279a2a57f403",
            "2f5e414979d8450babbad69409c5cd12",
            "7b48be0348a549e6b5b3917379df0af3",
            "212d4daf65f74507bb9052a43fcf1e31"
          ]
        },
        "id": "jeMPo8gvA0dT",
        "outputId": "d9a4832b-2bbf-46df-cc21-8494349f01ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48f723b8138e4d0ea673f3abb9f447c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SET TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N60xuyPsAYlN"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KkjG3EJ8d5a",
        "outputId": "70a02da2-c3d7-456e-9aeb-f5d710694495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['source', 'question', 'answer', 'context', 'language', 'label'],\n",
              "    num_rows: 15164\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe_completo = pd.read_csv(\"Datasets/out.csv\")\n",
        "ds_completo = Dataset.from_pandas(dataframe_completo)\n",
        "ds_completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CKtBjpsj_6oa"
      },
      "outputs": [],
      "source": [
        "y = dataframe_completo.loc[:,\"label\"]\n",
        "X = dataframe_completo.loc[:,\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjHbIunnAIHL"
      },
      "outputs": [],
      "source": [
        "X_train, X_to_split, y_train, y_to_split = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DCGVd7hPAJxH"
      },
      "outputs": [],
      "source": [
        "X_validation, X_test, y_validation, y_test = train_test_split(X_to_split, y_to_split, test_size=0.5, random_state=7, stratify=y_to_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4c3StYW2M2mp"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "validation_df = pd.concat([X_validation, y_validation], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5RK8JSPGNU_d",
        "outputId": "5340bc53-ce10-4a5d-e3bb-2d8e752d5226"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2404</th>\n",
              "      <td>Qual o dano nas algas está sendo causado pelo ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12654</th>\n",
              "      <td>Em que setor os empregos começam a diminuir?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13630</th>\n",
              "      <td>Quando foi estabelecida a Direção da Bibliotec...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2560</th>\n",
              "      <td>Em quais as áreas é esperado que o ruído antro...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582</th>\n",
              "      <td>Qual foi o tamanho da população da ilha de São...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7108</th>\n",
              "      <td>O Parque Nacional Monte Pascoal Ã© em qual bioma</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10031</th>\n",
              "      <td>Que tipo de floresta Ã© a selva amazÃ´nica?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12231</th>\n",
              "      <td>Quantos colonos originais se estabeleceram em ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>Onde as pinças de Mithraculis foram coletadas?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>Onde a noronha ela pode ser encontrada?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12131 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  label\n",
              "2404   Qual o dano nas algas está sendo causado pelo ...    1.0\n",
              "12654       Em que setor os empregos começam a diminuir?    0.0\n",
              "13630  Quando foi estabelecida a Direção da Bibliotec...    0.0\n",
              "2560   Em quais as áreas é esperado que o ruído antro...    1.0\n",
              "4582   Qual foi o tamanho da população da ilha de São...    1.0\n",
              "...                                                  ...    ...\n",
              "7108    O Parque Nacional Monte Pascoal Ã© em qual bioma    0.0\n",
              "10031        Que tipo de floresta Ã© a selva amazÃ´nica?    0.0\n",
              "12231  Quantos colonos originais se estabeleceram em ...    0.0\n",
              "379       Onde as pinças de Mithraculis foram coletadas?    1.0\n",
              "4897             Onde a noronha ela pode ser encontrada?    1.0\n",
              "\n",
              "[12131 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QChqRv2wNG9R"
      },
      "outputs": [],
      "source": [
        "train_ds = Dataset.from_pandas(train_df)\n",
        "validation_ds = Dataset.from_pandas(validation_df)\n",
        "test_ds = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e9rjWazNRNG",
        "outputId": "d3e5dc83-4422-46cf-fac0-efca240e4e84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'label', '__index_level_0__'],\n",
              "    num_rows: 12131\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qpTx5c70BU-g"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"question\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0f8a7527ca7b43c1a5e1671de0043f7e",
            "cb7536b28ef74e67b2b8dea42ee16868",
            "15977cab237640c59d4b18ed9aa2aa44",
            "9779416980964189b6b753640b9d29d0",
            "2d2e6b125b024a389c9178031b1ccd18",
            "225c031b0a374d5c88db76c1110131d5",
            "1b255027c53a4859b7abf4758be954e0",
            "1f0c6cd00d71483a8f0ff8d891511819",
            "09d6cd702d9f42c6954c22c5ef214423",
            "e8eab0459b14452ab74d2e2ef99de062",
            "99bd967bc55b495bb1765b8e2f547390",
            "7e8c417563ec4834aaea318eaa1f8274",
            "d01e630c655e41498e2054bf6e83be72",
            "7da0494f7a7248efbf2a839926108581",
            "5de067e0f7af4be885d030636c4c7574",
            "7355e59628e444b3b3c4251c726eaaff",
            "b58344a5deba44fe98903330123a7db0",
            "43b8fd5744ad43b4a70fd302090913ea",
            "80c07c5c48c341cf8d5cf8173aee00ab",
            "366f096b6ab043689750a1c3a1936202",
            "3f99550f12ec4139a693c611a59f1eab",
            "0f697b9792c54493b51ec7d7f5603155",
            "2f96e7981e8546c79ab6d57a7975ab95",
            "75ddf9e3eb33425e84bbf4caa3a20796",
            "69bca4d059be44cbb6160f4dc0b7a27f",
            "cace1b8f7f154c72ae70c44a9316aa05",
            "5c388a2078654ec68957c199008473af",
            "0d233ccf4f894056b9d1ad1ed781170b",
            "5690e7749960409b833107c926817ec0",
            "b5a85cae0ed2469880ee6f5b29701c71",
            "18ddbee7a5c54825a800ec31ca40b470",
            "ebd8872537c5459c91d3a7f47b956543",
            "57d7efc0d0384f68b5c605d71ad35e50"
          ]
        },
        "id": "5FrEfL32BrIa",
        "outputId": "189b14f5-0544-4e24-8e44-81d5f0f4c736"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "523d22dae440454bab56f99687897d2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12131 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "144d23ad3d6c49e9876ed5abfcc73a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1516 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e34d4af178495f9d36cb9a2e1200a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1517 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train_ds = train_ds.map(preprocess_function, batched=True)\n",
        "tekenized_validation_ds = validation_ds.map(preprocess_function, batched=True)\n",
        "tokenized_test_ds = test_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PIQMarQMJkS2"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "510u1g1LKP-A"
      },
      "outputs": [],
      "source": [
        "# f1_metric = evaluate.load(\"f1\")\n",
        "# accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bRhk4lW4Kbla"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uEwRFLm3L-eK"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TgUYG2-xLebd"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxykzrryLqIm",
        "outputId": "8a8f062d-798d-44c5-e06c-6d6feaba9294"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_primeiro is already a clone of https://huggingface.co/gustavokpc/IC_primeiro. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_primeiro is already a clone of https://huggingface.co/gustavokpc/IC_primeiro. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_primeiro\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model1.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U4vPXSOr8dl",
        "outputId": "4e911c11-ffea-4bac-ee8f-50af09972e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8498 - f1_m: 0.4723 - precision_m: 0.4085 - recall_m: 0.6530\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90369, saving model to model1.epoch01-accuracy0.90369.tf\n",
            "INFO:tensorflow:Assets written to: model1.epoch01-accuracy0.90369.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model1.epoch01-accuracy0.90369.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1522s 2s/step - loss: 0.3533 - accuracy: 0.8498 - f1_m: 0.4723 - precision_m: 0.4085 - recall_m: 0.6530 - val_loss: 0.2424 - val_accuracy: 0.9037 - val_f1_m: 0.5060 - val_precision_m: 0.3909 - val_recall_m: 0.7591\n",
            "Epoch 2/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9259 - f1_m: 0.5184 - precision_m: 0.3930 - recall_m: 0.8161\n",
            "Epoch 2: val_accuracy improved from 0.90369 to 0.92018, saving model to model1.epoch02-accuracy0.92018.tf\n",
            "INFO:tensorflow:Assets written to: model1.epoch02-accuracy0.92018.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model1.epoch02-accuracy0.92018.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1564s 2s/step - loss: 0.1974 - accuracy: 0.9259 - f1_m: 0.5184 - precision_m: 0.3930 - recall_m: 0.8161 - val_loss: 0.1978 - val_accuracy: 0.9202 - val_f1_m: 0.5425 - val_precision_m: 0.4014 - val_recall_m: 0.8778\n",
            "Epoch 3/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9551 - f1_m: 0.5382 - precision_m: 0.3974 - recall_m: 0.8918\n",
            "Epoch 3: val_accuracy improved from 0.92018 to 0.92480, saving model to model1.epoch03-accuracy0.92480.tf\n",
            "INFO:tensorflow:Assets written to: model1.epoch03-accuracy0.92480.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model1.epoch03-accuracy0.92480.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1556s 2s/step - loss: 0.1242 - accuracy: 0.9551 - f1_m: 0.5382 - precision_m: 0.3974 - recall_m: 0.8918 - val_loss: 0.1970 - val_accuracy: 0.9248 - val_f1_m: 0.5583 - val_precision_m: 0.4106 - val_recall_m: 0.9195\n",
            "Epoch 4/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9705 - f1_m: 0.5511 - precision_m: 0.4024 - recall_m: 0.9370\n",
            "Epoch 4: val_accuracy did not improve from 0.92480\n",
            "758/758 [==============================] - 1548s 2s/step - loss: 0.0823 - accuracy: 0.9705 - f1_m: 0.5511 - precision_m: 0.4024 - recall_m: 0.9370 - val_loss: 0.2550 - val_accuracy: 0.9116 - val_f1_m: 0.5567 - val_precision_m: 0.4057 - val_recall_m: 0.9330\n",
            "Epoch 5/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9812 - f1_m: 0.5544 - precision_m: 0.4027 - recall_m: 0.9558\n",
            "Epoch 5: val_accuracy did not improve from 0.92480\n",
            "758/758 [==============================] - 1631s 2s/step - loss: 0.0532 - accuracy: 0.9812 - f1_m: 0.5544 - precision_m: 0.4027 - recall_m: 0.9558 - val_loss: 0.2580 - val_accuracy: 0.9175 - val_f1_m: 0.5588 - val_precision_m: 0.4059 - val_recall_m: 0.9423\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x255e926d840>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8951187133789062, 0.9281002879142761, 0.9320580363273621, 0.9287598729133606, 0.9307388067245483]\n",
            "[0.5461256504058838, 0.5628437995910645, 0.5655707716941833, 0.5579412579536438, 0.5580920577049255]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model.history.history['val_accuracy']\n",
        "val_f1_m = model.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=5e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_segundo is already a clone of https://huggingface.co/gustavokpc/IC_segundo. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_segundo is already a clone of https://huggingface.co/gustavokpc/IC_segundo. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model2 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set2 = model2.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set2 = model2.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model2.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set2)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_segundo\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model2.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8399 - f1_m: 0.4604 - precision_m: 0.3607 - recall_m: 0.7042\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89974, saving model to model2.epoch01-accuracy0.89974.tf\n",
            "INFO:tensorflow:Assets written to: model2.epoch01-accuracy0.89974.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model2.epoch01-accuracy0.89974.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1853s 2s/step - loss: 0.3576 - accuracy: 0.8399 - f1_m: 0.4604 - precision_m: 0.3607 - recall_m: 0.7042 - val_loss: 0.2825 - val_accuracy: 0.8997 - val_f1_m: 0.5635 - val_precision_m: 0.4127 - val_recall_m: 0.9300\n",
            "Epoch 2/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.9274 - f1_m: 0.5204 - precision_m: 0.3849 - recall_m: 0.8616\n",
            "Epoch 2: val_accuracy improved from 0.89974 to 0.91755, saving model to model2.epoch02-accuracy0.91755.tf\n",
            "INFO:tensorflow:Assets written to: model2.epoch02-accuracy0.91755.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model2.epoch02-accuracy0.91755.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1789s 2s/step - loss: 0.2012 - accuracy: 0.9274 - f1_m: 0.5204 - precision_m: 0.3849 - recall_m: 0.8616 - val_loss: 0.2103 - val_accuracy: 0.9175 - val_f1_m: 0.5451 - val_precision_m: 0.3970 - val_recall_m: 0.9095\n",
            "Epoch 3/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9511 - f1_m: 0.5451 - precision_m: 0.3969 - recall_m: 0.9273\n",
            "Epoch 3: val_accuracy improved from 0.91755 to 0.93074, saving model to model2.epoch03-accuracy0.93074.tf\n",
            "INFO:tensorflow:Assets written to: model2.epoch03-accuracy0.93074.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model2.epoch03-accuracy0.93074.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1985s 3s/step - loss: 0.1312 - accuracy: 0.9511 - f1_m: 0.5451 - precision_m: 0.3969 - recall_m: 0.9273 - val_loss: 0.2125 - val_accuracy: 0.9307 - val_f1_m: 0.5571 - val_precision_m: 0.4017 - val_recall_m: 0.9523\n",
            "Epoch 4/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9690 - f1_m: 0.5547 - precision_m: 0.4007 - recall_m: 0.9557\n",
            "Epoch 4: val_accuracy did not improve from 0.93074\n",
            "758/758 [==============================] - 1807s 2s/step - loss: 0.0871 - accuracy: 0.9690 - f1_m: 0.5547 - precision_m: 0.4007 - recall_m: 0.9557 - val_loss: 0.2417 - val_accuracy: 0.9301 - val_f1_m: 0.5565 - val_precision_m: 0.4013 - val_recall_m: 0.9547\n",
            "Epoch 5/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9805 - f1_m: 0.5583 - precision_m: 0.4028 - recall_m: 0.9686\n",
            "Epoch 5: val_accuracy improved from 0.93074 to 0.93272, saving model to model2.epoch05-accuracy0.93272.tf\n",
            "INFO:tensorflow:Assets written to: model2.epoch05-accuracy0.93272.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model2.epoch05-accuracy0.93272.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1830s 2s/step - loss: 0.0559 - accuracy: 0.9805 - f1_m: 0.5583 - precision_m: 0.4028 - recall_m: 0.9686 - val_loss: 0.2533 - val_accuracy: 0.9327 - val_f1_m: 0.5605 - val_precision_m: 0.4028 - val_recall_m: 0.9674\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x255e50e4a30>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.fit(x=tf_train_set2, validation_data=tf_validation_set2, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9069920778274536, 0.9241424798965454, 0.9327176809310913]\n",
            "[0.5674652457237244, 0.5400716662406921, 0.5534441471099854]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model2.history.history['val_accuracy']\n",
        "val_f1_m = model2.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=3e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_terceiro is already a clone of https://huggingface.co/gustavokpc/IC_terceiro. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_terceiro is already a clone of https://huggingface.co/gustavokpc/IC_terceiro. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model3 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set3 = model3.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set3 = model3.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model3.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set3)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_terceiro\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model3.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8475 - f1_m: 0.5020 - precision_m: 0.4252 - recall_m: 0.7323\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87467, saving model to model3.epoch01-accuracy0.87467.tf\n",
            "INFO:tensorflow:Assets written to: model3.epoch01-accuracy0.87467.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model3.epoch01-accuracy0.87467.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1896s 2s/step - loss: 0.3546 - accuracy: 0.8475 - f1_m: 0.5020 - precision_m: 0.4252 - recall_m: 0.7323 - val_loss: 0.3033 - val_accuracy: 0.8747 - val_f1_m: 0.5815 - val_precision_m: 0.4266 - val_recall_m: 0.9558\n",
            "Epoch 2/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9344 - f1_m: 0.5389 - precision_m: 0.3987 - recall_m: 0.8912\n",
            "Epoch 2: val_accuracy improved from 0.87467 to 0.92612, saving model to model3.epoch02-accuracy0.92612.tf\n",
            "INFO:tensorflow:Assets written to: model3.epoch02-accuracy0.92612.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model3.epoch02-accuracy0.92612.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2022s 3s/step - loss: 0.1757 - accuracy: 0.9344 - f1_m: 0.5389 - precision_m: 0.3987 - recall_m: 0.8912 - val_loss: 0.2040 - val_accuracy: 0.9261 - val_f1_m: 0.5665 - val_precision_m: 0.4137 - val_recall_m: 0.9427\n",
            "Epoch 3/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9641 - f1_m: 0.5542 - precision_m: 0.4036 - recall_m: 0.9415\n",
            "Epoch 3: val_accuracy did not improve from 0.92612\n",
            "758/758 [==============================] - 1859s 2s/step - loss: 0.1004 - accuracy: 0.9641 - f1_m: 0.5542 - precision_m: 0.4036 - recall_m: 0.9415 - val_loss: 0.2133 - val_accuracy: 0.9222 - val_f1_m: 0.5610 - val_precision_m: 0.4087 - val_recall_m: 0.9424\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x256015708b0>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model3.fit(x=tf_train_set3, validation_data=tf_validation_set3, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8746702075004578, 0.9261213541030884, 0.9221636056900024]\n",
            "[0.5815335512161255, 0.5665431618690491, 0.5609732270240784]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model3.history.history['val_accuracy']\n",
        "val_f1_m = model3.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_quarto is already a clone of https://huggingface.co/gustavokpc/IC_quarto. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_quarto is already a clone of https://huggingface.co/gustavokpc/IC_quarto. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model4 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set4 = model4.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set4 = model4.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model4.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m]) # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set4)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_quarto\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model4.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8494 - f1_m: 0.4233 - precision_m: 0.3470 - recall_m: 0.6216\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89446, saving model to model4.epoch01-accuracy0.89446.tf\n",
            "INFO:tensorflow:Assets written to: model4.epoch01-accuracy0.89446.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model4.epoch01-accuracy0.89446.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2824s 4s/step - loss: 0.3469 - accuracy: 0.8494 - f1_m: 0.4233 - precision_m: 0.3470 - recall_m: 0.6216 - val_loss: 0.2535 - val_accuracy: 0.8945 - val_f1_m: 0.5613 - val_precision_m: 0.4145 - val_recall_m: 0.9125\n",
            "Epoch 2/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9335 - f1_m: 0.5237 - precision_m: 0.3895 - recall_m: 0.8572\n",
            "Epoch 2: val_accuracy improved from 0.89446 to 0.90172, saving model to model4.epoch02-accuracy0.90172.tf\n",
            "INFO:tensorflow:Assets written to: model4.epoch02-accuracy0.90172.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model4.epoch02-accuracy0.90172.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 3049s 4s/step - loss: 0.1742 - accuracy: 0.9335 - f1_m: 0.5237 - precision_m: 0.3895 - recall_m: 0.8572 - val_loss: 0.2315 - val_accuracy: 0.9017 - val_f1_m: 0.5765 - val_precision_m: 0.4256 - val_recall_m: 0.9353\n",
            "Epoch 3/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9634 - f1_m: 0.5432 - precision_m: 0.3978 - recall_m: 0.9159\n",
            "Epoch 3: val_accuracy improved from 0.90172 to 0.92348, saving model to model4.epoch03-accuracy0.92348.tf\n",
            "INFO:tensorflow:Assets written to: model4.epoch03-accuracy0.92348.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model4.epoch03-accuracy0.92348.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 3110s 4s/step - loss: 0.1061 - accuracy: 0.9634 - f1_m: 0.5432 - precision_m: 0.3978 - recall_m: 0.9159 - val_loss: 0.2101 - val_accuracy: 0.9235 - val_f1_m: 0.5596 - val_precision_m: 0.4070 - val_recall_m: 0.9389\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2560e0f00d0>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model4.fit(x=tf_train_set4, validation_data=tf_validation_set4, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8944591283798218, 0.9017150402069092, 0.9234828352928162]\n",
            "[0.5612534880638123, 0.5765007138252258, 0.5595895648002625]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model4.history.history['val_accuracy']\n",
        "val_f1_m = model4.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=1e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_quinto is already a clone of https://huggingface.co/gustavokpc/IC_quinto. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_quinto is already a clone of https://huggingface.co/gustavokpc/IC_quinto. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model5 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set5 = model5.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set5 = model5.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model5.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set5)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_quinto\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model5.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8160 - f1_m: 0.5002 - precision_m: 0.3900 - recall_m: 0.7694\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88588, saving model to model5.epoch01-accuracy0.88588.tf\n",
            "INFO:tensorflow:Assets written to: model5.epoch01-accuracy0.88588.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model5.epoch01-accuracy0.88588.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1913s 3s/step - loss: 0.4076 - accuracy: 0.8160 - f1_m: 0.5002 - precision_m: 0.3900 - recall_m: 0.7694 - val_loss: 0.2792 - val_accuracy: 0.8859 - val_f1_m: 0.5648 - val_precision_m: 0.4123 - val_recall_m: 0.9419\n",
            "Epoch 2/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9143 - f1_m: 0.5487 - precision_m: 0.4020 - recall_m: 0.9253\n",
            "Epoch 2: val_accuracy improved from 0.88588 to 0.89248, saving model to model5.epoch02-accuracy0.89248.tf\n",
            "INFO:tensorflow:Assets written to: model5.epoch02-accuracy0.89248.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model5.epoch02-accuracy0.89248.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2093s 3s/step - loss: 0.2272 - accuracy: 0.9143 - f1_m: 0.5487 - precision_m: 0.4020 - recall_m: 0.9253 - val_loss: 0.2778 - val_accuracy: 0.8925 - val_f1_m: 0.5752 - val_precision_m: 0.4181 - val_recall_m: 0.9630\n",
            "Epoch 3/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9419 - f1_m: 0.5524 - precision_m: 0.4019 - recall_m: 0.9429\n",
            "Epoch 3: val_accuracy improved from 0.89248 to 0.90699, saving model to model5.epoch03-accuracy0.90699.tf\n",
            "INFO:tensorflow:Assets written to: model5.epoch03-accuracy0.90699.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model5.epoch03-accuracy0.90699.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2434s 3s/step - loss: 0.1646 - accuracy: 0.9419 - f1_m: 0.5524 - precision_m: 0.4019 - recall_m: 0.9429 - val_loss: 0.2503 - val_accuracy: 0.9070 - val_f1_m: 0.5680 - val_precision_m: 0.4108 - val_recall_m: 0.9671\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x255f1cfb340>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model5.fit(x=tf_train_set5, validation_data=tf_validation_set5, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8858839273452759, 0.892480194568634, 0.9069920778274536]\n",
            "[0.5647614598274231, 0.5751519203186035, 0.567965030670166]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model5.history.history['val_accuracy']\n",
        "val_f1_m = model5.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  335141888 \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 335,143,938\n",
            "Trainable params: 335,143,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_sexto is already a clone of https://huggingface.co/gustavokpc/IC_sexto. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    model6 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        \"bert-large-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        "    )\n",
        "\n",
        "    model6.summary()\n",
        "\n",
        "    tf_train_set6 = model6.prepare_tf_dataset(\n",
        "        tokenized_train_ds,\n",
        "        shuffle=True,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    tf_validation_set6 = model6.prepare_tf_dataset(\n",
        "        tekenized_validation_ds,\n",
        "        shuffle=False,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "    model6.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m]) # No loss argument!\n",
        "    # metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set6)\n",
        "    push_to_hub_callback = PushToHubCallback(\n",
        "        output_dir=\"IC_sexto\",\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "    checkpoint = ModelCheckpoint(filepath = 'model6.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                                monitor = 'val_accuracy',\n",
        "                                verbose = 1,\n",
        "                                save_best_only = True,\n",
        "                                mode = 'max')\n",
        "    callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.8294 - f1_m: 0.3411 - precision_m: 0.2894 - recall_m: 0.4810\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89842, saving model to model6.epoch01-accuracy0.89842.tf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 829). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model6.epoch01-accuracy0.89842.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model6.epoch01-accuracy0.89842.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2857s 4s/step - loss: 0.3898 - accuracy: 0.8294 - f1_m: 0.3411 - precision_m: 0.2894 - recall_m: 0.4810 - val_loss: 0.2440 - val_accuracy: 0.8984 - val_f1_m: 0.5087 - val_precision_m: 0.3814 - val_recall_m: 0.8079\n",
            "Epoch 2/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9228 - f1_m: 0.4927 - precision_m: 0.3723 - recall_m: 0.7869\n",
            "Epoch 2: val_accuracy improved from 0.89842 to 0.92678, saving model to model6.epoch02-accuracy0.92678.tf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 829). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model6.epoch02-accuracy0.92678.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model6.epoch02-accuracy0.92678.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2899s 4s/step - loss: 0.2070 - accuracy: 0.9228 - f1_m: 0.4927 - precision_m: 0.3723 - recall_m: 0.7869 - val_loss: 0.1911 - val_accuracy: 0.9268 - val_f1_m: 0.5222 - val_precision_m: 0.3853 - val_recall_m: 0.8520\n",
            "Epoch 3/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9467 - f1_m: 0.5266 - precision_m: 0.3881 - recall_m: 0.8670\n",
            "Epoch 3: val_accuracy did not improve from 0.92678\n",
            "758/758 [==============================] - 4581s 6s/step - loss: 0.1392 - accuracy: 0.9467 - f1_m: 0.5266 - precision_m: 0.3881 - recall_m: 0.8670 - val_loss: 0.2310 - val_accuracy: 0.9057 - val_f1_m: 0.5617 - val_precision_m: 0.4162 - val_recall_m: 0.9092\n",
            "Epoch 4/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9570 - f1_m: 0.5387 - precision_m: 0.3946 - recall_m: 0.9100\n",
            "Epoch 4: val_accuracy did not improve from 0.92678\n",
            "758/758 [==============================] - 5044s 7s/step - loss: 0.1136 - accuracy: 0.9570 - f1_m: 0.5387 - precision_m: 0.3946 - recall_m: 0.9100 - val_loss: 0.2265 - val_accuracy: 0.9228 - val_f1_m: 0.5653 - val_precision_m: 0.4119 - val_recall_m: 0.9501\n",
            "Epoch 5/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9695 - f1_m: 0.5509 - precision_m: 0.4007 - recall_m: 0.9444\n",
            "Epoch 5: val_accuracy did not improve from 0.92678\n",
            "758/758 [==============================] - 4033s 5s/step - loss: 0.0832 - accuracy: 0.9695 - f1_m: 0.5509 - precision_m: 0.4007 - recall_m: 0.9444 - val_loss: 0.2387 - val_accuracy: 0.9248 - val_f1_m: 0.5604 - val_precision_m: 0.4074 - val_recall_m: 0.9461\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    model6.fit(x=tf_train_set6, validation_data=tf_validation_set6, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9096305966377258, 0.9274406433105469, 0.9228231906890869, 0.9221636056900024, 0.9215039610862732]\n",
            "[0.5641880035400391, 0.5641904473304749, 0.5681005120277405, 0.5714690089225769, 0.5709841847419739]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model6.history.history['val_accuracy']\n",
        "val_f1_m = model6.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_setimo is already a clone of https://huggingface.co/gustavokpc/IC_setimo. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    model7 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        \"bert-large-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        "    )\n",
        "\n",
        "    tf_train_set7 = model7.prepare_tf_dataset(\n",
        "        tokenized_train_ds,\n",
        "        shuffle=True,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    tf_validation_set7 = model7.prepare_tf_dataset(\n",
        "        tekenized_validation_ds,\n",
        "        shuffle=False,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "    model7.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "    # metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set7)\n",
        "    push_to_hub_callback = PushToHubCallback(\n",
        "        output_dir=\"IC_setimo\",\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "    checkpoint = ModelCheckpoint(filepath = 'model7.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                                monitor = 'val_accuracy',\n",
        "                                verbose = 1,\n",
        "                                save_best_only = True,\n",
        "                                mode = 'max')\n",
        "    callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8080 - f1_m: 0.4543 - precision_m: 0.3667 - recall_m: 0.6857\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89908, saving model to model7.epoch01-accuracy0.89908.tf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 829). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch01-accuracy0.89908.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch01-accuracy0.89908.tf\\assets\n",
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2860s 4s/step - loss: 0.4176 - accuracy: 0.8080 - f1_m: 0.4543 - precision_m: 0.3667 - recall_m: 0.6857 - val_loss: 0.2600 - val_accuracy: 0.8991 - val_f1_m: 0.5567 - val_precision_m: 0.4108 - val_recall_m: 0.9084\n",
            "Epoch 2/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9203 - f1_m: 0.5400 - precision_m: 0.3991 - recall_m: 0.8908\n",
            "Epoch 2: val_accuracy improved from 0.89908 to 0.92150, saving model to model7.epoch02-accuracy0.92150.tf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 829). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch02-accuracy0.92150.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch02-accuracy0.92150.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 2967s 4s/step - loss: 0.2122 - accuracy: 0.9203 - f1_m: 0.5400 - precision_m: 0.3991 - recall_m: 0.8908 - val_loss: 0.2049 - val_accuracy: 0.9215 - val_f1_m: 0.5529 - val_precision_m: 0.4068 - val_recall_m: 0.9089\n",
            "Epoch 3/3\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9523 - f1_m: 0.5559 - precision_m: 0.4041 - recall_m: 0.9513\n",
            "Epoch 3: val_accuracy improved from 0.92150 to 0.92216, saving model to model7.epoch03-accuracy0.92216.tf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 829). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch03-accuracy0.92216.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model7.epoch03-accuracy0.92216.tf\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 4082s 5s/step - loss: 0.1339 - accuracy: 0.9523 - f1_m: 0.5559 - precision_m: 0.4041 - recall_m: 0.9513 - val_loss: 0.2110 - val_accuracy: 0.9222 - val_f1_m: 0.5681 - val_precision_m: 0.4137 - val_recall_m: 0.9574\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    model7.fit(x=tf_train_set7, validation_data=tf_validation_set7, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.899076521396637, 0.9215039610862732, 0.9221636056900024]\n",
            "[0.5567145347595215, 0.5529072284698486, 0.568143367767334]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model7.history.history['val_accuracy']\n",
        "val_f1_m = model7.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_oitavo is already a clone of https://huggingface.co/gustavokpc/IC_oitavo. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_oitavo is already a clone of https://huggingface.co/gustavokpc/IC_oitavo. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model8 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set8 = model8.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set8 = model8.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model8.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set8)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_oitavo\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model8.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'Adam/Adam/update_192/mul_1' defined at (most recent call last):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_16644\\1063932975.py\", line 1, in <module>\n      model8.fit(x=tf_train_set8, validation_data=tf_validation_set8, epochs=num_epochs, callbacks=callbacks)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1675, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 770, in apply_grad_to_update_var\n      return self._resource_apply_sparse_duplicate_indices(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 1453, in _resource_apply_sparse_duplicate_indices\n      return self._resource_apply_sparse(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 217, in _resource_apply_sparse\n      m, m * coefficients[\"beta_1_t\"], use_locking=self._use_locking\nNode: 'Adam/Adam/update_192/mul_1'\nfailed to allocate memory\n\t [[{{node Adam/Adam/update_192/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_423883]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_validation_set8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/Adam/update_192/mul_1' defined at (most recent call last):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_16644\\1063932975.py\", line 1, in <module>\n      model8.fit(x=tf_train_set8, validation_data=tf_validation_set8, epochs=num_epochs, callbacks=callbacks)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1675, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 770, in apply_grad_to_update_var\n      return self._resource_apply_sparse_duplicate_indices(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 1453, in _resource_apply_sparse_duplicate_indices\n      return self._resource_apply_sparse(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 217, in _resource_apply_sparse\n      m, m * coefficients[\"beta_1_t\"], use_locking=self._use_locking\nNode: 'Adam/Adam/update_192/mul_1'\nfailed to allocate memory\n\t [[{{node Adam/Adam/update_192/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_423883]"
          ]
        }
      ],
      "source": [
        "model8.fit(x=tf_train_set8, validation_data=tf_validation_set8,--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8891820311546326, 0.9142480492591858, 0.9135884046554565]\n",
            "[0.5707703232765198, 0.5582769513130188, 0.5594871640205383]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model8.history.history['val_accuracy']\n",
        "val_f1_m = model8.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_nono is already a clone of https://huggingface.co/gustavokpc/IC_nono. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_nono is already a clone of https://huggingface.co/gustavokpc/IC_nono. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model9 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set9 = model9.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set9 = model9.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model9.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set9)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_nono\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model9.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "758/758 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8256 - f1_m: 0.4970 - precision_m: 0.3813 - recall_m: 0.7827"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 1444s 2s/step - loss: 0.3792 - accuracy: 0.8256 - f1_m: 0.4970 - precision_m: 0.3813 - recall_m: 0.7827 - val_loss: 0.2438 - val_accuracy: 0.9116 - val_f1_m: 0.5469 - val_precision_m: 0.3963 - val_recall_m: 0.9240\n",
            "Epoch 2/5\n",
            "758/758 [==============================] - 1377s 2s/step - loss: 0.2147 - accuracy: 0.9128 - f1_m: 0.5383 - precision_m: 0.3958 - recall_m: 0.8972 - val_loss: 0.2278 - val_accuracy: 0.9109 - val_f1_m: 0.5656 - val_precision_m: 0.4104 - val_recall_m: 0.9530\n",
            "Epoch 3/5\n",
            "758/758 [==============================] - 1310s 2s/step - loss: 0.1597 - accuracy: 0.9357 - f1_m: 0.5504 - precision_m: 0.4004 - recall_m: 0.9353 - val_loss: 0.1952 - val_accuracy: 0.9228 - val_f1_m: 0.5613 - val_precision_m: 0.4056 - val_recall_m: 0.9564\n",
            "Epoch 4/5\n",
            "758/758 [==============================] - 1261s 2s/step - loss: 0.1200 - accuracy: 0.9530 - f1_m: 0.5532 - precision_m: 0.4016 - recall_m: 0.9526 - val_loss: 0.1926 - val_accuracy: 0.9294 - val_f1_m: 0.5623 - val_precision_m: 0.4058 - val_recall_m: 0.9582\n",
            "Epoch 5/5\n",
            "758/758 [==============================] - 1263s 2s/step - loss: 0.0943 - accuracy: 0.9644 - f1_m: 0.5581 - precision_m: 0.4039 - recall_m: 0.9630 - val_loss: 0.2071 - val_accuracy: 0.9301 - val_f1_m: 0.5646 - val_precision_m: 0.4068 - val_recall_m: 0.9665\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel9\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set9\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_validation_set9\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1865\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_tune_steps_per_execution:\n\u001b[0;32m   1864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m-> 1865\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\callbacks.py:541\u001b[0m, in \u001b[0;36mCallbackList.on_train_end\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    539\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 541\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\keras_callbacks.py:399\u001b[0m, in \u001b[0;36mPushToHubCallback.on_train_end\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    397\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPushing the last epoch to the Hub, this may take a while...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_job\u001b[38;5;241m.\u001b[39mis_done:\n\u001b[1;32m--> 399\u001b[0m         \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model9.fit(x=tf_train_set9, validation_data=tf_validation_set9, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_acc = model9.history.history['val_accuracy']\n",
        "val_f1_m = model9.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 7\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=1e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_10 is already a clone of https://huggingface.co/gustavokpc/IC_10. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_10 is already a clone of https://huggingface.co/gustavokpc/IC_10. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model10 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-large-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set10 = model10.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set10 = model10.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model10.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set10)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_10\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model10.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose' defined at (most recent call last):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_16644\\1029347792.py\", line 1, in <module>\n      model10.fit(x=tf_train_set10, validation_data=tf_validation_set10, epochs=num_epochs, callbacks=callbacks)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"The old compute_loss method is deprecated as it conflicts with the Keras compute_loss \"\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1569, in call\n      outputs = self.bert(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"The old compute_loss method is deprecated as it conflicts with the Keras compute_loss \"\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 862, in call\n      encoder_outputs = self.encoder(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 548, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      layer_outputs = layer_module(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 464, in call\n      self_attention_outputs = self.attention(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 380, in call\n      self_outputs = self.self_attention(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 278, in call\n      if is_cross_attention and past_key_value is not None:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 283, in call\n      elif is_cross_attention:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 287, in call\n      elif past_key_value is not None:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 293, in call\n      key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 257, in transpose_for_scores\n      return tf.transpose(tensor, perm=[0, 2, 1, 3])\nNode: 'tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose'\nOOM when allocating tensor with shape[16,16,95,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_399786]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_validation_set10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose' defined at (most recent call last):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gusta\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_16644\\1029347792.py\", line 1, in <module>\n      model10.fit(x=tf_train_set10, validation_data=tf_validation_set10, epochs=num_epochs, callbacks=callbacks)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"The old compute_loss method is deprecated as it conflicts with the Keras compute_loss \"\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1569, in call\n      outputs = self.bert(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n      \"The old compute_loss method is deprecated as it conflicts with the Keras compute_loss \"\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 862, in call\n      encoder_outputs = self.encoder(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 548, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      layer_outputs = layer_module(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 464, in call\n      self_attention_outputs = self.attention(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 380, in call\n      self_outputs = self.self_attention(\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 278, in call\n      if is_cross_attention and past_key_value is not None:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 283, in call\n      elif is_cross_attention:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 287, in call\n      elif past_key_value is not None:\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 293, in call\n      key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size)\n    File \"c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 257, in transpose_for_scores\n      return tf.transpose(tensor, perm=[0, 2, 1, 3])\nNode: 'tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose'\nOOM when allocating tensor with shape[16,16,95,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_bert_for_sequence_classification_1/bert/encoder/layer_._8/attention/self/transpose}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_399786]"
          ]
        }
      ],
      "source": [
        "model10.fit(x=tf_train_set10, validation_data=tf_validation_set10, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8608179688453674, 0.892480194568634, 0.916886568069458, 0.9221636056900024, 0.9109498858451843, 0.9155672788619995, 0.920844316482544]\n",
            "[0.5444657802581787, 0.5735011100769043, 0.5532918572425842, 0.5650185942649841, 0.5663719177246094, 0.5573129057884216, 0.5605470538139343]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model10.history.history['val_accuracy']\n",
        "val_f1_m = model10.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 7\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=5e-6, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Cloning https://huggingface.co/gustavokpc/IC_11 into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/gustavokpc/IC_11 into local empty directory.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9eee52a58b94cf4a2c25a4390a720c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Download file tf_model.h5:   0%|          | 16.0k/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c271aded1a544f69603408f99d221be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clean file tf_model.h5:   0%|          | 1.00k/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model11 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-large-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set11 = model11.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set11 = model11.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model11.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set11)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_11\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model11.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "758/758 [==============================] - 3910s 5s/step - loss: 0.4434 - accuracy: 0.8014 - f1_m: 0.4236 - precision_m: 0.3661 - recall_m: 0.5865 - val_loss: 0.2743 - val_accuracy: 0.8872 - val_f1_m: 0.4964 - val_precision_m: 0.3787 - val_recall_m: 0.7644\n",
            "Epoch 2/7\n",
            "758/758 [==============================] - 3755s 5s/step - loss: 0.2804 - accuracy: 0.8901 - f1_m: 0.4898 - precision_m: 0.3778 - recall_m: 0.7488 - val_loss: 0.2824 - val_accuracy: 0.8879 - val_f1_m: 0.5567 - val_precision_m: 0.4181 - val_recall_m: 0.8782\n",
            "Epoch 3/7\n",
            "758/758 [==============================] - 3752s 5s/step - loss: 0.2254 - accuracy: 0.9128 - f1_m: 0.5069 - precision_m: 0.3838 - recall_m: 0.8028 - val_loss: 0.2388 - val_accuracy: 0.9090 - val_f1_m: 0.5468 - val_precision_m: 0.4009 - val_recall_m: 0.9053\n",
            "Epoch 4/7\n",
            "758/758 [==============================] - 3725s 5s/step - loss: 0.1873 - accuracy: 0.9303 - f1_m: 0.5203 - precision_m: 0.3889 - recall_m: 0.8490 - val_loss: 0.2200 - val_accuracy: 0.9149 - val_f1_m: 0.5561 - val_precision_m: 0.4075 - val_recall_m: 0.9235\n",
            "Epoch 5/7\n",
            "758/758 [==============================] - 3720s 5s/step - loss: 0.1614 - accuracy: 0.9404 - f1_m: 0.5316 - precision_m: 0.3944 - recall_m: 0.8756 - val_loss: 0.2188 - val_accuracy: 0.9235 - val_f1_m: 0.5566 - val_precision_m: 0.4080 - val_recall_m: 0.9242\n",
            "Epoch 6/7\n",
            "758/758 [==============================] - 3720s 5s/step - loss: 0.1380 - accuracy: 0.9497 - f1_m: 0.5359 - precision_m: 0.3956 - recall_m: 0.8898 - val_loss: 0.2205 - val_accuracy: 0.9228 - val_f1_m: 0.5506 - val_precision_m: 0.4024 - val_recall_m: 0.9213\n",
            "Epoch 7/7\n",
            "758/758 [==============================] - 3669s 5s/step - loss: 0.1200 - accuracy: 0.9569 - f1_m: 0.5414 - precision_m: 0.3981 - recall_m: 0.9034 - val_loss: 0.2290 - val_accuracy: 0.9202 - val_f1_m: 0.5513 - val_precision_m: 0.4022 - val_recall_m: 0.9261\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1c62415e740>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model11.fit(x=tf_train_set11, validation_data=tf_validation_set11, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8872031569480896, 0.8878628015518188, 0.9089709520339966, 0.9149076342582703, 0.9234828352928162, 0.9228231906890869, 0.9201846718788147]\n",
            "[0.49644768238067627, 0.5567076206207275, 0.5467871427536011, 0.5560939908027649, 0.5565869212150574, 0.5505979061126709, 0.5513056516647339]\n"
          ]
        }
      ],
      "source": [
        "val_acc = model11.history.history['val_accuracy']\n",
        "val_f1_m = model11.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=5e-6, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "c:\\Users\\gusta\\Documents\\IC\\IC_12 is already a clone of https://huggingface.co/gustavokpc/IC_12. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:c:\\Users\\gusta\\Documents\\IC\\IC_12 is already a clone of https://huggingface.co/gustavokpc/IC_12. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ],
      "source": [
        "model12 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set12 = model12.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set12 = model12.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model12.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set12)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_12\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model12.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "663/758 [=========================>....] - ETA: 7:56 - loss: 0.4071 - accuracy: 0.8133 - f1_m: 0.4281 - precision_m: 0.3614 - recall_m: 0.6192"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel12\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_validation_set12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model12.fit(x=tf_train_set12, validation_data=tf_validation_set12, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_acc = model12.history.history['val_accuracy']\n",
        "val_f1_m = model12.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model13 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set13 = model13.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set13 = model13.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model13.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set13)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_13\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model13.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model13.fit(x=tf_train_set13, validation_data=tf_validation_set13, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_acc = model13.history.history['val_accuracy']\n",
        "val_f1_m = model13.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(X_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=6e-6, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model14 = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "tf_train_set14 = model14.prepare_tf_dataset(\n",
        "    tokenized_train_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set14 = model14.prepare_tf_dataset(\n",
        "    tekenized_validation_ds,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "model14.compile(optimizer=optimizer, metrics=['accuracy', f1_m, precision_m, recall_m])  # No loss argument!\n",
        "# metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set14)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"IC_14\",\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(filepath = 'model14.epoch{epoch:02d}-accuracy{val_accuracy:.5f}.tf',\n",
        "                             monitor = 'val_accuracy',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "callbacks = [checkpoint, push_to_hub_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model14.fit(x=tf_train_set14, validation_data=tf_validation_set14, epochs=num_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_acc = model14.history.history['val_accuracy']\n",
        "val_f1_m = model14.history.history['val_f1_m']\n",
        "print(val_acc)\n",
        "print(val_f1_m)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02ca282163e84911a6bbb5a89e6cb8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebad54fcdb4f401b87690e111a76241e",
            "placeholder": "​",
            "style": "IPY_MODEL_943bf451794b4a98ac34d22ff3e18153",
            "value": "Token is valid (permission: write)."
          }
        },
        "09d6cd702d9f42c6954c22c5ef214423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c80641d1bfc43aaa140a02d234ab218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f05997c4ee42529f8c43685a7c88d9",
            "placeholder": "​",
            "style": "IPY_MODEL_8ffea4a72f2a42d194eea491ba3522e1",
            "value": "Connecting..."
          }
        },
        "0d233ccf4f894056b9d1ad1ed781170b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f697b9792c54493b51ec7d7f5603155": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8a7527ca7b43c1a5e1671de0043f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb7536b28ef74e67b2b8dea42ee16868",
              "IPY_MODEL_15977cab237640c59d4b18ed9aa2aa44",
              "IPY_MODEL_9779416980964189b6b753640b9d29d0"
            ],
            "layout": "IPY_MODEL_2d2e6b125b024a389c9178031b1ccd18"
          }
        },
        "13314f40c2cc45e2b3bd279a2a57f403": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15977cab237640c59d4b18ed9aa2aa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0c6cd00d71483a8f0ff8d891511819",
            "max": 12131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09d6cd702d9f42c6954c22c5ef214423",
            "value": 12131
          }
        },
        "18ddbee7a5c54825a800ec31ca40b470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b04d96bc5ca472382d87b25dd00e76a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b255027c53a4859b7abf4758be954e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf403a3b41b434899b24e55158d9001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a95d32b93d8444be88b23e6951b8d079",
            "style": "IPY_MODEL_ad80b1c96a2b43a1b53bfe2880eea49f",
            "value": true
          }
        },
        "1f0c6cd00d71483a8f0ff8d891511819": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2026e5a1dc9b488b9a45cdbbdedfec8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212d4daf65f74507bb9052a43fcf1e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225c031b0a374d5c88db76c1110131d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e24c02abfb4f90bc07dde978849110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2e6b125b024a389c9178031b1ccd18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc69d8658aa4196ada660c98e20c4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13314f40c2cc45e2b3bd279a2a57f403",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5e414979d8450babbad69409c5cd12",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "2f5e414979d8450babbad69409c5cd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f96e7981e8546c79ab6d57a7975ab95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ddf9e3eb33425e84bbf4caa3a20796",
              "IPY_MODEL_69bca4d059be44cbb6160f4dc0b7a27f",
              "IPY_MODEL_cace1b8f7f154c72ae70c44a9316aa05"
            ],
            "layout": "IPY_MODEL_5c388a2078654ec68957c199008473af"
          }
        },
        "366f096b6ab043689750a1c3a1936202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "372c4e4950ee4122b5b6d0dcde672d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3a397ebb3c744a14bd764df19b5e7b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2026e5a1dc9b488b9a45cdbbdedfec8c",
            "style": "IPY_MODEL_372c4e4950ee4122b5b6d0dcde672d56",
            "tooltip": ""
          }
        },
        "3f99550f12ec4139a693c611a59f1eab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b8fd5744ad43b4a70fd302090913ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "475713ce145f4fc1beab59de46892f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5690e7749960409b833107c926817ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d7efc0d0384f68b5c605d71ad35e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c388a2078654ec68957c199008473af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de067e0f7af4be885d030636c4c7574": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f99550f12ec4139a693c611a59f1eab",
            "placeholder": "​",
            "style": "IPY_MODEL_0f697b9792c54493b51ec7d7f5603155",
            "value": " 1516/1516 [00:00&lt;00:00, 7369.04 examples/s]"
          }
        },
        "69bca4d059be44cbb6160f4dc0b7a27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a85cae0ed2469880ee6f5b29701c71",
            "max": 1517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18ddbee7a5c54825a800ec31ca40b470",
            "value": 1517
          }
        },
        "7355e59628e444b3b3c4251c726eaaff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ddf9e3eb33425e84bbf4caa3a20796": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d233ccf4f894056b9d1ad1ed781170b",
            "placeholder": "​",
            "style": "IPY_MODEL_5690e7749960409b833107c926817ec0",
            "value": "Map: 100%"
          }
        },
        "765c03d7611841e18cd064ee0f07ea6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_475713ce145f4fc1beab59de46892f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_c20138bfc36c4942a887f9c097c2e3f8",
            "value": ""
          }
        },
        "79d1820f406c4bad995f06db705021e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b13e05ab95240509c7e1790c9b1fbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7b48be0348a549e6b5b3917379df0af3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da0494f7a7248efbf2a839926108581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c07c5c48c341cf8d5cf8173aee00ab",
            "max": 1516,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_366f096b6ab043689750a1c3a1936202",
            "value": 1516
          }
        },
        "7e8c417563ec4834aaea318eaa1f8274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d01e630c655e41498e2054bf6e83be72",
              "IPY_MODEL_7da0494f7a7248efbf2a839926108581",
              "IPY_MODEL_5de067e0f7af4be885d030636c4c7574"
            ],
            "layout": "IPY_MODEL_7355e59628e444b3b3c4251c726eaaff"
          }
        },
        "808cdc93356d41f79eb0fa1975495921": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c07c5c48c341cf8d5cf8173aee00ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffea4a72f2a42d194eea491ba3522e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f05997c4ee42529f8c43685a7c88d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943bf451794b4a98ac34d22ff3e18153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9779416980964189b6b753640b9d29d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8eab0459b14452ab74d2e2ef99de062",
            "placeholder": "​",
            "style": "IPY_MODEL_99bd967bc55b495bb1765b8e2f547390",
            "value": " 12131/12131 [00:03&lt;00:00, 1749.90 examples/s]"
          }
        },
        "99bd967bc55b495bb1765b8e2f547390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a034f64f0a9944088944dd21e67e83df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b48be0348a549e6b5b3917379df0af3",
            "placeholder": "​",
            "style": "IPY_MODEL_212d4daf65f74507bb9052a43fcf1e31",
            "value": "Login successful"
          }
        },
        "a95d32b93d8444be88b23e6951b8d079": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad80b1c96a2b43a1b53bfe2880eea49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc3f442c128481cac2145f1b88e2982": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d012a7fc1a1d4d139c21cdd452183c09",
            "placeholder": "​",
            "style": "IPY_MODEL_79d1820f406c4bad995f06db705021e2",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b58344a5deba44fe98903330123a7db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a85cae0ed2469880ee6f5b29701c71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20138bfc36c4942a887f9c097c2e3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cace1b8f7f154c72ae70c44a9316aa05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd8872537c5459c91d3a7f47b956543",
            "placeholder": "​",
            "style": "IPY_MODEL_57d7efc0d0384f68b5c605d71ad35e50",
            "value": " 1517/1517 [00:00&lt;00:00, 6345.25 examples/s]"
          }
        },
        "cb21581ed1f546f6b340b843a51b3d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b04d96bc5ca472382d87b25dd00e76a",
            "placeholder": "​",
            "style": "IPY_MODEL_23e24c02abfb4f90bc07dde978849110",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "cb7536b28ef74e67b2b8dea42ee16868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225c031b0a374d5c88db76c1110131d5",
            "placeholder": "​",
            "style": "IPY_MODEL_1b255027c53a4859b7abf4758be954e0",
            "value": "Map: 100%"
          }
        },
        "d012a7fc1a1d4d139c21cdd452183c09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01e630c655e41498e2054bf6e83be72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b58344a5deba44fe98903330123a7db0",
            "placeholder": "​",
            "style": "IPY_MODEL_43b8fd5744ad43b4a70fd302090913ea",
            "value": "Map: 100%"
          }
        },
        "d07b4922d6c04754a96de47fd62033aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8eab0459b14452ab74d2e2ef99de062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebad54fcdb4f401b87690e111a76241e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd8872537c5459c91d3a7f47b956543": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9ce7b5e22a455996c0eb94918d201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808cdc93356d41f79eb0fa1975495921",
            "placeholder": "​",
            "style": "IPY_MODEL_d07b4922d6c04754a96de47fd62033aa",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f5996a197da4490ea9d90911b63f6db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02ca282163e84911a6bbb5a89e6cb8e0",
              "IPY_MODEL_cb21581ed1f546f6b340b843a51b3d10",
              "IPY_MODEL_2dc69d8658aa4196ada660c98e20c4cd",
              "IPY_MODEL_a034f64f0a9944088944dd21e67e83df"
            ],
            "layout": "IPY_MODEL_7b13e05ab95240509c7e1790c9b1fbb5"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
